{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Multiple Kernel Learning using SHOGUN\n",
    "\n",
    "Le but de ce Notebook est d'expliquer, étapes par étapes, ce que réalise ce code, inspiré de l'exemple fourni par Shogun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principe du Multiple Kernel Learning\n",
    "\n",
    "Un algorithme de Multiple Kernel Learning (MKL) a pour but de combiner plusieurs kernels, de façon optimale, en vue d'optimiser la prédiction du classifieur.\n",
    "\n",
    "Avoir recours au MKL peut avoir deux intérêts :\n",
    "- Proposer plusieurs kernels au \"Learner\" pour un même jeu de données, afin que celui-ci puisse choisir le ou les kernels adapté(s)\n",
    "- Avoir recours à plusieurs données hétérogènes auxquelles sont associées un ou plusieurs kernels, et pouvoir les combiner pour bénéficier de ces différentes sources d'information. \n",
    "\n",
    "Sur Shogun, le \"Learner\" utilisé est la SVM. \n",
    "Pour la partie MKL, Shogun pose un problème d'optimisation dans lequel il va tenter de minimiser la somme de deux termes : un terme d'erreur et un terme de complexité. Il s'agit de la méthode de minimisation des risques structurels. \n",
    "Il recherche ainsi à résoudre un problème en formulation SILP (Semi-Infinite Linear Programming), et suit pour cela une méthode en deux étapes : \n",
    "- dans la première, il optimise le vecteur de poids des kernels\n",
    "- dans la deuxième, il trouve les paramètres de la SVM \n",
    "\n",
    "Ces deux itérations s'enchaînent jusqu'à convergence. \n",
    "\n",
    "##### La section suivante explicite plus en détail le problème d'optimisation résolu par Shogun. Il s'agit d'un développement théorique. Passez à la section suivante pour l'explication du code. \n",
    "\n",
    "Pour mieux comprendre le fonctionnement de cette librairie, on peut s'interesser à la façon dont le problème de classification est résolu. \n",
    "\n",
    "Il s'agit en fait de reformuler le problème sous une forme SILP, c'est-à-dire que la fonction objectif et les contraintes seront linéaires, mais qu'il y a une infinité de contraintes.\n",
    "\n",
    "Ces contraintes sont relatives aux valeurs alpha des multiplicateurs lagrangiens du problème posé par la SVM. Ces valeurs peuvent varier sur le segment [0 ; C] (où C représente le coût de la classification). Il y a donc une infinité de possibilités. \n",
    "\n",
    "Pour résoudre le problème, l'algorithme va fonctionner en deux étapes.\n",
    "- Il va tout d'abord prendre un lot fini de contraintes et trouver la solution optimale du sous-problème ainsi posé.\n",
    "- Il entre alors dans la deuxième étape, où il va générer, à partir de la solution de la première étape, la contrainte la plus sévère parmi l'ensemble des contraintes inexploitées. \n",
    "- Cette contrainte est alors ajoutée au lot de contraintes de la première étape.\n",
    "    - Si la contrainte est satisfaite, alors cela veut dire que la solution est optimale, et l'algorithme s'arrête\n",
    "    - Si la contrainte n'est pas satisfaite, alors on trouve une nouvelle solution au sous-problème et on reboucle. \n",
    "    \n",
    "Le critère d'arrêt de l'algorithme est donc lié à la valeur de la violation de la contrainte la plus sévère. On définit ainsi un seuil mkl_epsilon, tel que, si la valeur de la violation est inférieure à ce seuil, alors on considère que la solution est optimale. \n",
    "\n",
    "Voyons maintenant en quoi consiste l'algorithme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/global/anaconda2/lib/python27.zip', '/home/global/anaconda2/lib/python2.7', '/home/global/anaconda2/lib/python2.7/plat-linux2', '/home/global/anaconda2/lib/python2.7/lib-tk', '/home/global/anaconda2/lib/python2.7/lib-old', '/home/global/anaconda2/lib/python2.7/lib-dynload', '/home/romain/.local/lib/python2.7/site-packages', '/home/global/anaconda2/lib/python2.7/site-packages', '/home/global/anaconda2/lib/python2.7/site-packages/Sphinx-1.5.6-py2.7.egg', '/home/global/anaconda2/lib/python2.7/site-packages/pydot_ng-1.0.1.dev0-py2.7.egg', '/home/global/anaconda2/lib/python2.7/site-packages/setuptools-27.2.0-py2.7.egg', '/home/global/anaconda2/lib/python2.7/site-packages/IPython/extensions', '/home/romain/.ipython', '/usr/local/lib/python2.7/site-packages/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "shogun_path=\"/usr/local/lib/python2.7/site-packages/\"\n",
    "sys.path.append(shogun_path)\n",
    "print(sys.path)\n",
    "from modshogun import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "from scipy.io import loadmat, savemat\n",
    "from os       import path, sep\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir importé les éléments dont nous avons besoin pour faire fonctionner l'algorithme, nous définissons nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat  = loadmat('/NAS/dumbo/protocoles/CogPhenoPark/data/cogphenoparkCli3.mat')\n",
    "mat2  = loadmat('/NAS/dumbo/protocoles/CogPhenoPark/data/cogphenopark_New.mat')\n",
    "mat3 = loadmat('/NAS/dumbo/protocoles/CogPhenoPark/data/cogphenopark_anova.mat') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons ensuite deux éléments : \n",
    "- une matrice X qui contient l'ensemble des features de nos patients, de dimension nb_features x nb_individus\n",
    "- un vecteur Y qui contient les classes (ou labels) de chaque individu, i.e un vecteur ligne de dimension nb_individus\n",
    "\n",
    "Précisons que si nous avons plus de 2 classes, il faut attribuer à chacune d'entre elle un nombre entier, en partant de 0. (0, 1, 2, ...)\n",
    "\n",
    "Par ailleurs, si on travaille sur plusieurs jeux de données, alors on définit plusieurs vecteurs X, à raison de un pour chaque jeu de features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 112)\n",
      "(13366, 112)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  4.\n",
      "  4.  4.  4.  4.]\n"
     ]
    }
   ],
   "source": [
    "Xall1 = mat['dataCli']\n",
    "Xall2 = mat2['newData']\n",
    "#Xall2 = mat3['data']\n",
    "\n",
    "Yall = array(mat['label'].squeeze(), dtype=double)\n",
    "\n",
    "print Xall1.shape\n",
    "print Xall2.shape\n",
    "\n",
    "Yall = Yall - 1\n",
    "#on fait partir nos classes de 0\n",
    "\n",
    "print Yall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche générale\n",
    "\n",
    "On explique ici le principe de l'algorithme.\n",
    "Celui-ci étant amené à fonctionner en Leave-one-out, on se fixe un i pour étudier ce que fait l'algorithme lors d'une itération. \n",
    "\n",
    "On définit une liste d'indices \"ind\" qui fait la même taille que notre vecteur des labels Y. Si la longueur de Y est n, alors ind sera la liste des entiers de 0 à n-1 [0, ..., n-1]. Cela ne présente pas de problème pour python, le premier élément d'une liste est l'élément d'indice 0. On ne perd donc pas d'individu avec cette démarche.\n",
    "\n",
    "De cette liste, on va extraire le i-ème élément, qui sera l'indice de notre élément de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111]\n"
     ]
    }
   ],
   "source": [
    "i = 40 \n",
    "ind = range (len(Yall))\n",
    "del ind[i]\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit maintenant la matrice de nos données d'entraînement, Xtrain, à raison de 1 pour chaque jeu de features. \n",
    "Si le but est de réaliser du Leave-one-out, il suffit de reprendre l'ensemble de nos lignes (qui correspondent à nos features), ainsi que toutes les colonnes de la liste ind (c'est à dire toutes sauf la i-ème). \n",
    "\n",
    "On définit également notre vecteur label Ytrain associé à nos données d'entraînement de la même façon.\n",
    "\n",
    "Afin de reconnaître les différentes classes contenues dans Ytrain, on utlise la fonction MulticlassLabels().\n",
    "Cette fonction n'est utile que dans le cas d'un nombre de classes supérieur à 2. Il faut faire appel à une autre fonction pour la classification binaire.\n",
    "\n",
    "De même, on extrait les features de nos données contenues dans Xtrain à l'aide de la fonction Realfeatures(). Cette fonction est la même, que l'on soit en binaire ou en multi-classes. \n",
    "\n",
    "Enfin, on refait les mêmes opérations pour nos données de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75]\n"
     ]
    }
   ],
   "source": [
    "#modif de romain \n",
    "#Sain\n",
    "test=where(Yall==3)[0]\n",
    "Xall2[200,test]=1\n",
    "\n",
    "#grave\n",
    "test=where(Yall==4)[0]\n",
    "Xall2[200,test]=0\n",
    "\n",
    "#MCI\n",
    "test=where(Yall==0)[0]\n",
    "Xall2[200,test]=0.2\n",
    "\n",
    "#sévère\n",
    "test=where(Yall==1)[0]\n",
    "Xall2[200,test]=0.4\n",
    "\n",
    "#leger\n",
    "test=where(Yall==2)[0]\n",
    "Xall2[200,test]=0.7\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain1 = Xall1[:,ind]\n",
    "Xtrain2 = Xall2[:,ind]\n",
    "\n",
    "Ytrain = Yall[ind]\n",
    "\n",
    "labels = MulticlassLabels(Ytrain)\n",
    "\n",
    "feats1  = RealFeatures(Xtrain1)\n",
    "feats2  = RealFeatures(Xtrain2)\n",
    "\n",
    "Xrem1 = Xall1[:, i:i+1]\n",
    "Xrem2 = Xall2[:, i:i+1]\n",
    "\n",
    "Yrem = Yall[i:i+1]\n",
    "\n",
    "labels_rem = MulticlassLabels(Yrem)\n",
    "\n",
    "feats_rem1 = RealFeatures(Xrem1)\n",
    "feats_rem2 = RealFeatures(Xrem2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit ici de nouvelles variables.\n",
    "\n",
    "La fonction CombinedFeatures() permet de créer une liste de l'ensemble des features associées à chacun de nos jeux de données, tout en gardant un pointeur vers le kernel auquel ces features sont associées. \n",
    "Par exemple, si j'ai un total de deux kernels associés chacun à un jeu de features, la fonction CombinedFeature() contiendra toutes les features, divisées en 2 sous-lots pointant chacun vers leur kernel respectif. \n",
    "\n",
    "Parallèlement, la fonction CombinedKernel() contiendra tous les kernels que l'on souhaite utiliser dans notre classification. \n",
    "\n",
    "Précision : \n",
    "\n",
    "Si l'on souhaite utiliser plusieurs kernels sur un même jeu de données, il y a 2 possibilités :\n",
    "- la fonction CombinedFeatures() peut prendre autant de sous-lots de features qu'il y a de kernels (tous les sous-lots seront alors identiques)\n",
    "- on peut ne donner qu'un unique lot à la fonction CombinedFeatures, qui sera par défaut associé à l'ensemble des kernels contenus dans CombinedKernels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats_train = CombinedFeatures()\n",
    "feats_test = CombinedFeatures()\n",
    "combined_kernel = CombinedKernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shogun dispose de nombreux types de kernels. Les plus fréquemment utilisés restent cependant les kernels Gaussiens, Polynomiaux et Linéaires. \n",
    "\n",
    "- Pour le kernel Gaussien, il n'y a qu'un hyperparamètre à fixer : la largeur de bande.\n",
    "- Pour le kernel Polynomial, il y a deux hyperparamètres : le premier correspond au coefficient dans l'expression du kernel polynomial, et le deuxième au degré. \n",
    "\n",
    "Il est important de préciser, à chaque fois qu'un kernel est créé, le jeu de features auquel il est rattaché, et d'intégrer celui-ci au CombinedFeatures(). \n",
    "De même, le kernel doit être incorporé au CombinedKernel(). \n",
    "\n",
    "Quelques informations sur les hyperparamètres :\n",
    "\n",
    "Plus on diminue la largeur de bande d'un kernel Gaussien, plus on se rapproche d'un comportement linéaire.\n",
    "Plus on l'augmente, plus on risque l'overfeating sur nos données d'entraînement.\n",
    "\n",
    "Pour visualiser ce comportement, consulter : https://remi.flamary.com/demos/svmreg.fr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append gaussian kernel\n",
    "\n",
    "subkernel = GaussianKernel(0.1)        \n",
    "feats_train.append_feature_obj(feats1)\n",
    "feats_test.append_feature_obj(feats_rem1)\n",
    "combined_kernel.append_kernel(subkernel)\n",
    "\n",
    "#append PolyKernel\n",
    "\n",
    "subkernel = PolyKernel(5,3)            \n",
    "feats_train.append_feature_obj(feats1)\n",
    "feats_test.append_feature_obj(feats_rem1)\n",
    "combined_kernel.append_kernel(subkernel)\n",
    "    \n",
    "#append Linear Kernel\n",
    "\n",
    "subkernel = LinearKernel()            \n",
    "feats_train.append_feature_obj(feats1)\n",
    "feats_test.append_feature_obj(feats_rem1)\n",
    "combined_kernel.append_kernel(subkernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase d'entraînement\n",
    "\n",
    "La fonction init() permet de lancer l'algorithme. Pour cela, on lui précise deux bases.\n",
    "La première base correspond à la base d'entraînement. La deuxième dépend de ce que l'on souhaite faire :\n",
    "- si on veut réaliser l'entraînement, on précise à nouveau la base d'entraînement\n",
    "- si on veut réaliser le test, on précise la base de test.\n",
    "\n",
    "La fonction MKLMulticlass(C, K, l) prends en arguments le coût C de la classification, le CombinedKernel() et l'ensemble des labels. \n",
    "\n",
    "C'est à l'utilisateur de fixer la valeur de C, qui peut avoir une influence sur la qualité de la classification.\n",
    "\n",
    "Le paramètre mkl_epsilon renvoit au critère d'arrêt du problème d'optimisation. Plus celui-ci est faible, plus on se rapproche de la solution optimale du problème d'optimisation. Mais cela augmente également le temps d'éxécution de l'algorithme.\n",
    "\n",
    "Enfin, mkl_norm renvoie à la contrainte que l'on impose sur la somme des poids des kernels. En effet, en norme 1, on impose que la somme des poids soit égale à un, mais on pourrait tout aussi bien imposer que la somme des carrés des poids soit égale à 1, et on utiliserait pour cela la norme 2 (cela permettrait d'avoir une pondération dense des kernels, par opposition à la solution sparse que renvoie la normalisation L1).\n",
    "\n",
    "Enfin, l'entraînement est réalisé avec la fonction train()\n",
    "\n",
    "Précisions sur l'hyperparamètre C :\n",
    "\n",
    "C est un hyperparamètre qui influence à la quantité d'erreurs de classifications que s'autorise le classifieur. Plus C est grand, plus on autorise d'erreurs. Toutefois, le problème d'optimisation sur lequel s'appuie la classification vise à minimiser la valeur de ces erreurs. Par conséquent plus C est grand, plus il y a d'erreurs à minimiser et plus la complexité de l'algorithme augmente. Mais en contrepartie, si notre problème est non séparable, alors il est nécessaire de s'autoriser un minimum d'erreurs de classification afin d'être capable de trouver un hyperplan séparateur. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_kernel.init(feats_train, feats_train)\n",
    "mkl = MKLMulticlass(1.2, combined_kernel, labels)\n",
    "\n",
    "#kl.set_mkl_epsilon(1e-5)\n",
    "mkl.set_mkl_norm(1)\n",
    "\n",
    "#Pour la classification binaire\n",
    "    \n",
    "#mkl = MKLClassification()\n",
    "#mkl.set_C(1, 1)\n",
    "#mkl.set_kernel(combined_kernel)\n",
    "#mkl.set_labels(labels)\n",
    "    \n",
    "mkl.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase de test\n",
    "\n",
    "On utilise maintenant la fonction init() pour réaliser notre test sur l'élément d'indice i. \n",
    "\n",
    "La fonction apply() permet de faire fonctionner l'algorithme pour nos données de test. On stocke la prédiction dans une variable 'out'.\n",
    "\n",
    "On peut remonter à la valeur de l'exactitude en comparant notre variable de sortie 'out' avec les valeurs de prédiction attendues stockées dans label_rem. pour cela on utilise les fonctions MulticlassAccuracy() et evaluate()\n",
    "\n",
    "Il peut également être interessant de visulatiser les poids attribués à chacun de nos kernels, via la fonction get_subkernel_weights()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91723355  0.          0.08276645]\n",
      "Accuracy globale = 100.00%\n"
     ]
    }
   ],
   "source": [
    "combined_kernel.init(feats_train, feats_test)     \n",
    "\n",
    "out =  mkl.apply()\n",
    "evaluator = MulticlassAccuracy()\n",
    "\n",
    "acc = evaluator.evaluate(out, labels_rem)\n",
    "    \n",
    "w = combined_kernel.get_subkernel_weights()\n",
    "    \n",
    "print w\n",
    "    \n",
    "print \"Accuracy globale = %2.2f%%\" % (100*acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode de Leave-one-out\n",
    "\n",
    "Afin de réaliser du Leave-one-out, nous avons construit la méthode suivante :\n",
    "\n",
    "- A chaque itération de la boucle for, on retire le i-ème élément de ind, qui constituera notre élément de test. \n",
    "\n",
    "-  le vecteur de poids peut être amené à varier (l'optimisation est refaite à chaque fois). On peut donc volontairement le visualiser à chaque fois, pour constater son évolution entre chaque itération.\n",
    "\n",
    "- En fonction du résultat de la prédiction (0 si mal classé, 1 si bien classé), on augmente la valeur de accuracy_globale, qui, une fois rapportée à la taille de l'effectif, permettra d'évaluer l'exactitude sur l'ensemble des prédictions.\n",
    "\n",
    "- On peut également faire la même chose pour chaque classe individuelle. Il suffit pour cela de connaître leur effectif. \n",
    "\n",
    "- On peut aussi remonter à la prédiction que fait notre algorithme grâce à la fonction get_labels().\n",
    "\n",
    "Afin d'évaluer la durée d'éxécution de toute cette étape, il peut être bon de relever le temps affiché par l'horloge au début (tic) et à la fin (toc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13366, 112)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xall2.shape\n",
    "\n",
    "#for j in range(len(Yall)) :\n",
    "#    feats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "Accuracy globale = 71.43%\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "prediction = []\n",
    "accuracy_globale = 0\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "#LOO\n",
    "\n",
    "for i in range(len(Yall)) :\n",
    "    print i\n",
    "    ind = range (len(Yall))\n",
    "    del ind[i]\n",
    "\n",
    "    Xtrain1 = Xall1[:,ind]\n",
    "    Xtrain2 = Xall2[0:10000,ind]\n",
    "\n",
    "    Ytrain = Yall[ind]\n",
    "\n",
    "    labels = MulticlassLabels(Ytrain)\n",
    "\n",
    "    feats1  = RealFeatures(Xtrain1)\n",
    "    feats2  = RealFeatures(Xtrain2)\n",
    "\n",
    "    Xrem1 = Xall1[:, i:i+1]\n",
    "    Xrem2 = Xall2[0:10000, i:i+1]\n",
    "\n",
    "    Yrem = Yall[i:i+1]\n",
    "\n",
    "    labels_rem = MulticlassLabels(Yrem)\n",
    "\n",
    "    feats_rem1 = RealFeatures(Xrem1)\n",
    "    feats_rem2 = RealFeatures(Xrem2)\n",
    "    \n",
    "# MKL training and output\n",
    "\n",
    "    feats_train = CombinedFeatures()\n",
    "    feats_test = CombinedFeatures()\n",
    "    combined_kernel = CombinedKernel()\n",
    "\n",
    "\n",
    "##### Pour le premier jeu de features ######    \n",
    "\n",
    "# remarque : avec les kernels pris individuellement, on arrive à 82% d'exactitude pour un kernel gaussien (11)\n",
    "# remarque 2 : dès qu'on met un deuxième kernel avec lui, l'exactitude tombe à 79,46% si on garde la même valeur de C = 1.2\n",
    "# remarque 3 : avec le même kernel gaussien + un linéraire + un polynomial, on retrouve nos 82,14% en passant à C = 10\n",
    "       \n",
    "#append gaussian kernel (le meilleur kernel pour ce jeu de feature)\n",
    "\n",
    "    subkernel = GaussianKernel(11)        \n",
    "    feats_train.append_feature_obj(feats1)\n",
    "    feats_test.append_feature_obj(feats_rem1)\n",
    "    combined_kernel.append_kernel(subkernel)\n",
    "    \n",
    "#append gaussian kernel\n",
    "\n",
    "    #subkernel = GaussianKernel(0.1)        \n",
    "    #feats_train.append_feature_obj(feats1)\n",
    "    #feats_test.append_feature_obj(feats_rem1)\n",
    "    #combined_kernel.append_kernel(subkernel)\n",
    "    \n",
    "\n",
    "#append PolyKernel\n",
    "\n",
    "    #subkernel = PolyKernel(10,3)            \n",
    "    #feats_train.append_feature_obj(feats1)\n",
    "    #feats_test.append_feature_obj(feats_rem1)\n",
    "    #combined_kernel.append_kernel(subkernel)\n",
    "    \n",
    "#append Linear Kernel\n",
    "\n",
    "    #subkernel = LinearKernel()            \n",
    "    #feats_train.append_feature_obj(feats1)\n",
    "    #feats_test.append_feature_obj(feats_rem1)\n",
    "    #combined_kernel.append_kernel(subkernel)\n",
    "\n",
    "\n",
    "##### Pour le deuxième jeu de features ######    \n",
    "    \n",
    "#append gaussian kernel\n",
    "    for index_j in range(0,len(Xtrain2),50) :\n",
    "        subkernel = GaussianKernel(1)\n",
    "        Xtmp=Xtrain2[index_j:index_j+50,:]\n",
    "        feats2  = RealFeatures(Xtmp)\n",
    "        feats_train.append_feature_obj(feats2)\n",
    "        \n",
    "        Xtmp2=Xrem2[index_j:index_j+50,:]\n",
    "        feats_rem2= RealFeatures(Xtmp2)\n",
    "        feats_test.append_feature_obj(feats_rem2)\n",
    "        \n",
    "        combined_kernel.append_kernel(subkernel) \n",
    "\n",
    "#append PolyKernel\n",
    "\n",
    "    #subkernel = PolyKernel(10,3)            \n",
    "    #feats_train.append_feature_obj(feats1)\n",
    "    #feats_test.append_feature_obj(feats_rem1)\n",
    "    #combined_kernel.append_kernel(subkernel)\n",
    "    \n",
    "#append Linear Kernel\n",
    "\n",
    "    #subkernel = LinearKernel()            \n",
    "    #feats_train.append_feature_obj(feats2)\n",
    "    #feats_test.append_feature_obj(feats_rem2)\n",
    "    #combined_kernel.append_kernel(subkernel)\n",
    "\n",
    "\n",
    "    combined_kernel.init(feats_train, feats_train)\n",
    "    \n",
    "    mkl = MKLMulticlass(10, combined_kernel, labels)\n",
    "\n",
    "    #mkl.set_epsilon(1e-2)\n",
    "    mkl.set_mkl_epsilon(1e-3)\n",
    "    mkl.set_mkl_norm(1)\n",
    "    \n",
    "    mkl.train()\n",
    "\n",
    "#MKL Test\n",
    "    \n",
    "    combined_kernel.init(feats_train, feats_test)     \n",
    "\n",
    "    out =  mkl.apply()\n",
    "    evaluator = MulticlassAccuracy()\n",
    "\n",
    "    acc = evaluator.evaluate(out, labels_rem)\n",
    "    accuracy.append(acc)\n",
    "    accuracy_globale = accuracy_globale + acc\n",
    "    \n",
    "    w = combined_kernel.get_subkernel_weights()\n",
    "    \n",
    "    prediction.append(out.get_labels().tolist())\n",
    "    #z = out.get_values()\n",
    "    \n",
    "    #print w\n",
    "    \n",
    "print \"Accuracy globale = %2.2f%%\" % (100*accuracy_globale/len(Yall))\n",
    "\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy par classe :\n",
      "Classe 0 = 87.80%\n",
      "Classe 1 = 0.00%\n",
      "Classe 2 = 58.62%\n",
      "Classe 3 = 90.00%\n",
      "Classe 4 = 0.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy_0 = 0\n",
    "accuracy_1 = 0\n",
    "accuracy_2 = 0\n",
    "accuracy_3 = 0\n",
    "accuracy_4 = 0\n",
    "\n",
    "print \"Accuracy par classe :\"\n",
    "\n",
    "for j in range (41) :\n",
    "    accuracy_0 = accuracy_0 + accuracy[j]\n",
    "\n",
    "print \"Classe 0 = %2.2f%%\" % (100*accuracy_0/41)\n",
    "\n",
    "for k in range (41, 47) :\n",
    "    accuracy_1 = accuracy_1 + accuracy[k]\n",
    "\n",
    "print \"Classe 1 = %2.2f%%\" % (100*accuracy_1/6)\n",
    "\n",
    "for l in range (47, 76) :\n",
    "    accuracy_2 = accuracy_2 + accuracy[l]\n",
    "\n",
    "print \"Classe 2 = %2.2f%%\" % (100*accuracy_2/29)\n",
    "\n",
    "for m in range (76,106) :\n",
    "    accuracy_3 = accuracy_3 + accuracy[m]\n",
    "\n",
    "print \"Classe 3 = %2.2f%%\" % (100*accuracy_3/30)\n",
    "\n",
    "for n in range (106,112) :\n",
    "    accuracy_4 = accuracy_4 + accuracy[n]\n",
    "\n",
    "print \"Classe 4 = %2.2f%%\" % (100*accuracy_4/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [2.0], [2.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [2.0], [2.0], [0.0], [0.0], [0.0], [0.0], [2.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [2.0], [2.0], [2.0], [2.0], [2.0], [0.0], [2.0], [0.0], [2.0], [2.0], [2.0], [0.0], [0.0], [2.0], [2.0], [2.0], [2.0], [3.0], [2.0], [3.0], [2.0], [2.0], [2.0], [2.0], [2.0], [3.0], [0.0], [2.0], [2.0], [2.0], [3.0], [3.0], [3.0], [2.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [3.0], [0.0], [3.0], [3.0], [3.0], [3.0], [3.0], [0.0], [4.0], [0.0], [4.0], [4.0]]\n"
     ]
    }
   ],
   "source": [
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps écoulé = \n",
      "367.033513069\n"
     ]
    }
   ],
   "source": [
    "print \"Temps écoulé = \" \n",
    "print toc-tic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
